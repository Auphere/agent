# Sistema de Memoria de ConversaciÃ³n - Arquitectura v2.0

## ğŸ¯ Resumen Ejecutivo

Este documento describe el nuevo sistema de memoria de conversaciÃ³n diseÃ±ado para resolver el problema de "memoria inconsistente" que afectaba al agente. El sistema anterior (v1) tenÃ­a problemas porque:

1. **PlanMemoryManager** usaba singleton en memoria â†’ se perdÃ­a entre workers/reinicios
2. **ConversationMemory** tenÃ­a race conditions y cachÃ© inconsistente
3. **No habÃ­a estrategia clara** de ventana de contexto y compresiÃ³n

El nuevo sistema (v2) es **production-grade**, inspirado en Cursor, Perplexity y OpenAI, con:

- âœ… Persistencia en base de datos (PostgreSQL)
- âœ… CachÃ© inteligente con Redis
- âœ… Ventana deslizante con compresiÃ³n automÃ¡tica
- âœ… 3 niveles de memoria (working, short-term, long-term)
- âœ… Compatible con mÃºltiples workers/procesos

---

## ğŸ—ï¸ Arquitectura del Sistema

### Componentes Principales

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Agent Request Handler                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     MemoryManager                            â”‚
â”‚  - Orquestador principal                                     â”‚
â”‚  - Interfaz de alto nivel                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                       â”‚
       â–¼                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ConversationBuffer  â”‚            â”‚   ContextBuilder        â”‚
â”‚                     â”‚            â”‚                         â”‚
â”‚ - Carga contexto    â”‚            â”‚ - Construye prompts     â”‚
â”‚ - Gestiona ventana  â”‚            â”‚ - Formatea mensajes     â”‚
â”‚ - Comprime memoria  â”‚            â”‚ - Extrae estado plan    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Persistence Layer                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚  PostgreSQL  â”‚      â”‚    Redis     â”‚                    â”‚
â”‚  â”‚  (Source of  â”‚      â”‚  (Fast       â”‚                    â”‚
â”‚  â”‚   Truth)     â”‚      â”‚   Cache)     â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ MÃ³dulos y Responsabilidades

### 1. `conversation_buffer.py`

**Clase Principal: `ConversationBuffer`**

Responsable de cargar y gestionar el contexto de conversaciÃ³n desde la base de datos y cachÃ©.

**CaracterÃ­sticas:**

- âœ… Carga contexto con ventana deslizante configurable
- âœ… CompresiÃ³n automÃ¡tica cuando se excede el presupuesto de tokens
- âœ… CachÃ© en Redis para respuestas rÃ¡pidas (5 min TTL)
- âœ… Extrae lugares mencionados para resoluciÃ³n de referencias
- âœ… Genera resÃºmenes de conversaciones largas

**ConfiguraciÃ³n por Defecto:**

```python
DEFAULT_SHORT_TERM_TURNS = 10   # Ãšltimos 10 turnos en detalle completo
DEFAULT_LONG_TERM_TURNS = 50    # Hasta 50 turnos para resumen
DEFAULT_MAX_TOKENS = 4000       # Presupuesto mÃ¡ximo de tokens
COMPRESSION_THRESHOLD = 0.8     # Comprime al 80% del presupuesto
```

**MÃ©todos Clave:**

- `load_context()`: Punto de entrada principal - carga todo el contexto
- `_build_from_database()`: Construye contexto desde DB (slow path)
- `_compress_context()`: Comprime contexto cuando excede lÃ­mite
- `invalidate_cache()`: Invalida cachÃ© despuÃ©s de nuevo mensaje

**Ejemplo de Uso:**

```python
buffer = ConversationBuffer(repository=repo, cache=cache)

context = await buffer.load_context(
    user_id=user_uuid,
    session_id=session_uuid,
    current_query="Busca bares cerca de Sol",
    current_language="es"
)
# context.recent_messages contiene los Ãºltimos mensajes
# context.previous_places contiene lugares mencionados
# context.session_summary contiene resumen de conversaciÃ³n larga
```

---

### 2. `context_builder.py`

**Clase Principal: `ContextBuilder`**

Responsable de construir prompts optimizados para LLMs a partir del contexto cargado.

**CaracterÃ­sticas:**

- âœ… Formatea mensajes para LangChain (SystemMessage, HumanMessage, AIMessage)
- âœ… Inyecta referencias a lugares para resoluciÃ³n de ambigÃ¼edades
- âœ… Mejora system prompts con contexto de sesiÃ³n
- âœ… Genera tanto formato de mensajes como strings

**MÃ©todos Clave:**

- `build_messages()`: Construye lista de BaseMessage para agentes
- `build_string_context()`: Construye string de contexto (legacy)
- `build_agent_context_dict()`: Construye dict completo para agentes
- `extract_plan_state()`: Extrae estado de plan desde metadata de DB

**Ejemplo de Uso:**

```python
builder = ContextBuilder()

messages = builder.build_messages(
    context=conv_context,
    system_prompt="Eres un asistente de viajes..."
)
# messages = [SystemMessage, ...history..., HumanMessage]

agent_context = builder.build_agent_context_dict(
    context=conv_context,
    validated_context=user_location_context
)
# Contiene: history_messages, previous_places, session_summary, etc.
```

**Clase Auxiliar: `PlanContextExtractor`**

Reemplaza el antiguo `PlanMemoryManager` con un enfoque basado en DB.

- `extract_from_query()`: Extrae parÃ¡metros de plan desde query con heurÃ­sticas
- `merge_plan_state()`: Combina nuevo estado con existente
- `is_plan_ready()`: Verifica si plan tiene todos los campos requeridos
- `format_missing_fields_prompt()`: Genera pregunta amigable para campos faltantes

---

### 3. `memory.py` (Actualizado)

**Clase Principal: `MemoryManager`**

Interfaz de alto nivel que orquesta `ConversationBuffer` y `ContextBuilder`.

**MÃ©todo Principal:**

```python
async def build_agent_context(
    user_id: UUID,
    session_id: UUID,
    current_query: str,
    include_history: bool = True,
    include_patterns: bool = False,
    current_language: str = "es",
) -> dict
```

**Retorna:**

```python
{
    "user_id": "...",
    "session_id": "...",
    "current_query": "...",
    "language": "es",

    # Memoria (nuevo sistema)
    "history_messages": [HumanMessage(...), AIMessage(...)],
    "conversation_history": "Usuario: ... Asistente: ...",
    "previous_places": [{name: "...", _turn_number: 2}],

    # Resumen de sesiÃ³n
    "session_summary": "ConversaciÃ³n previa: 15 mensajes...",
    "total_turns": 15,

    # Token budget
    "estimated_tokens": 1200,
    "tokens_remaining": 2800,

    # Opcional
    "user_patterns": {...},
    "validated_context": {...}
}
```

---

## ğŸ”„ Flujo de EjecuciÃ³n

### Request de Usuario â†’ Respuesta del Agente

```
1. Usuario envÃ­a mensaje
   â†“
2. API Route recibe request
   â†“
3. MemoryManager.build_agent_context()
   â†“
4. ConversationBuffer.load_context()
   - Intenta cachÃ© (Redis) â†’ HIT? â†’ Retorna
   - MISS? â†’ Consulta DB
   - Construye ConversationContext
   - Comprime si necesario
   - Guarda en cachÃ©
   â†“
5. ContextBuilder.build_agent_context_dict()
   - Formatea mensajes
   - Inyecta referencias
   - Prepara contexto
   â†“
6. Supervisor/Agent ejecuta con contexto
   â†“
7. Guarda respuesta en DB
   â†“
8. MemoryManager.invalidate_session_cache()
   - Invalida cachÃ© de Redis
   â†“
9. Siguiente mensaje usa DB actualizado
```

---

## ğŸ¨ Niveles de Memoria

### Level 1: Working Memory (Turno Actual)

- **QuÃ© es**: Query actual del usuario
- **DuraciÃ³n**: Solo el turno actual
- **PropÃ³sito**: Contexto inmediato

### Level 2: Short-term Memory (Reciente)

- **QuÃ© es**: Ãšltimos N turnos (default: 10)
- **DuraciÃ³n**: Hasta exceder presupuesto de tokens
- **Almacenamiento**: DB + Redis cache (5 min)
- **PropÃ³sito**: Mantener coherencia conversacional

### Level 3: Long-term Memory (HistÃ³rico)

- **QuÃ© es**: Resumen de turnos anteriores
- **DuraciÃ³n**: Hasta 50 turnos histÃ³ricos
- **Almacenamiento**: DB (generado on-demand)
- **PropÃ³sito**: PersonalizaciÃ³n y contexto de sesiÃ³n larga

---

## ğŸ”§ ConfiguraciÃ³n y OptimizaciÃ³n

### Variables de Entorno

```bash
# Redis (recomendado para producciÃ³n)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# PostgreSQL
DATABASE_URL=postgresql://...
```

### Tunning de ParÃ¡metros

**Para conversaciones cortas (< 10 mensajes):**

```python
ConversationBuffer(
    max_short_term_turns=5,
    max_long_term_turns=20,
    max_tokens=2000
)
```

**Para conversaciones largas (> 30 mensajes):**

```python
ConversationBuffer(
    max_short_term_turns=15,
    max_long_term_turns=100,
    max_tokens=6000
)
```

**Para ambientes con workers limitados:**

- Aumentar CACHE_TTL_SHORT a 600 (10 min)
- Reducir max_short_term_turns a 5
- Habilitar compresiÃ³n agresiva

---

## ğŸš€ MigraciÃ³n desde Sistema Antiguo

### Paso 1: Actualizar Dependencias

El sistema ya estÃ¡ actualizado en:

- âœ… `memory.py` - MemoryManager usa ConversationBuffer internamente
- âœ… `react_agent.py` - Ya no usa PlanMemoryManager
- âœ… `streaming_routes.py` - Pasa `current_language` y invalida cachÃ©
- âœ… Plan state se guarda en `ConversationTurn.extra_metadata`

### Paso 2: No Requiere Cambios en API

El sistema mantiene **backward compatibility**:

- La interfaz `MemoryManager.build_agent_context()` es la misma
- El formato de retorno es compatible (aÃ±ade campos nuevos)
- Los agentes existentes funcionan sin cambios

### Paso 3: Deprecated Modules

**NO USAR:**

- âŒ `PlanMemoryManager` - Reemplazado por `PlanContextExtractor`
- âŒ `ConversationMemory` directamente - Usar `ConversationBuffer`

**USAR:**

- âœ… `MemoryManager.build_agent_context()` - Interfaz principal
- âœ… `ConversationBuffer` - Para casos de uso avanzados
- âœ… `ContextBuilder` - Para formateo personalizado de prompts

---

## ğŸ§ª Testing y ValidaciÃ³n

### Test de Memoria Persistente

```python
# 1. Enviar mensaje
response = await agent.query("Busca bares en Madrid")

# 2. Enviar seguimiento (mismo session_id)
response = await agent.query("Dame mÃ¡s info del segundo")
# âœ… Debe recordar los bares del mensaje anterior

# 3. Reiniciar workers
# 4. Enviar otro seguimiento
response = await agent.query("Y el primero?")
# âœ… Debe seguir recordando (desde DB, no memoria)
```

### Test de CompresiÃ³n

```python
# Enviar 20 mensajes largos
for i in range(20):
    await agent.query(f"Mensaje largo nÃºmero {i}...")

# Verificar logs
# âœ… Debe ver "context_compressed" en logs
# âœ… Token count debe mantenerse < max_tokens
```

### Test de Cache Invalidation

```python
# 1. Enviar mensaje
await agent.query("Hola")

# 2. Verificar cachÃ© (debe existir)
cache_key = f"conversation_context:{session_id}"
cached = await redis.get(cache_key)
# âœ… cached != None

# 3. Enviar otro mensaje
await agent.query("CÃ³mo estÃ¡s?")

# 4. Verificar cachÃ© invalidado
# âœ… Sistema debe haber invalidado y recreado cachÃ©
```

---

## ğŸ“Š Monitoreo y Debugging

### Logs Importantes

**Carga de contexto exitosa:**

```
INFO: context_loaded_from_database
  session_id=...
  recent_turns=10
  estimated_tokens=1500
```

**Cache hit:**

```
DEBUG: context_loaded_from_cache
  session_id=...
```

**CompresiÃ³n activada:**

```
INFO: context_needs_compression
  estimated_tokens=3500
  max_tokens=4000
```

**Memoria invÃ¡lida (problema):**

```
WARNING: conversation_buffer_load_failed
ERROR: database_connection_check_failed
```

### MÃ©tricas a Monitorear

1. **Cache Hit Rate**: Debe ser > 60% en producciÃ³n
2. **Compression Frequency**: < 10% de requests
3. **Average Tokens**: Debe mantenerse estable
4. **DB Query Time**: < 50ms para get_session_history

---

## ğŸ› Troubleshooting

### Problema: "El agente no recuerda conversaciones anteriores"

**Causa posible:**

1. Session_id cambia entre requests
2. DB commits no se estÃ¡n ejecutando
3. Cache invalidation no funciona

**SoluciÃ³n:**

```python
# Verificar session_id consistente
logger.info("session_id", session_id=str(session_id))

# Verificar commit despuÃ©s de save_turn
await conversation_repo.save_turn(...)
await session.commit()  # â† CRÃTICO

# Verificar invalidaciÃ³n de cachÃ©
await memory_manager.invalidate_session_cache(session_id)
```

### Problema: "Memory excede token limit"

**Causa posible:**

1. max_tokens muy bajo
2. CompresiÃ³n deshabilitada
3. Mensajes extremadamente largos

**SoluciÃ³n:**

```python
# Aumentar presupuesto
ConversationBuffer(max_tokens=6000)

# Reducir ventana
ConversationBuffer(max_short_term_turns=5)

# Verificar logs de compresiÃ³n
# Debe ver "context_compressed" cuando se acerca al lÃ­mite
```

### Problema: "Plan context se pierde"

**Causa posible:**

1. Extra_metadata no se guarda correctamente
2. PlanContextExtractor no extrae campos

**SoluciÃ³n:**

```python
# Verificar metadata en DB
turn = await repo.get_turn_by_id(turn_id)
assert turn.extra_metadata is not None
assert "plan_params" in turn.extra_metadata

# Mejorar extracciÃ³n
from src.agents.context_builder import PlanContextExtractor
extracted = PlanContextExtractor.extract_from_query(query, "es")
# Verificar que extrae correctamente
```

---

## ğŸ¯ Best Practices

### âœ… DO

1. **Siempre usar MemoryManager** como interfaz principal
2. **Commit inmediatamente** despuÃ©s de save_turn
3. **Invalidar cachÃ©** despuÃ©s de guardar nuevo mensaje
4. **Usar session_id consistente** a lo largo de la conversaciÃ³n
5. **Monitorear token usage** en logs
6. **Guardar plan state** en extra_metadata

### âŒ DON'T

1. **No usar PlanMemoryManager** (deprecated)
2. **No modificar ConversationBuffer** sin entender flujo completo
3. **No saltarse cache invalidation**
4. **No asumir que cachÃ© estÃ¡ actualizado** siempre
5. **No usar memoria in-process** para estado compartido
6. **No exceder max_tokens** sin comprimir

---

## ğŸ“š Referencias

### InspiraciÃ³n

- **Cursor**: Sistema de memoria con ventana deslizante
- **Perplexity**: CompresiÃ³n inteligente de contexto
- **OpenAI Assistants**: Threads + mensajes persistentes
- **LangChain**: MessageHistory + ConversationBuffer

### DocumentaciÃ³n Relacionada

- `src/agents/conversation_buffer.py` - ImplementaciÃ³n completa
- `src/agents/context_builder.py` - Formateo de prompts
- `src/database/repositories.py` - Persistencia de turnos
- `api/streaming_routes.py` - IntegraciÃ³n en API

---

## ğŸ”® Roadmap Futuro

### Mejoras Planificadas

1. **Summarization con LLM** (en lugar de rule-based)

   - Usar GPT-4 para resumir conversaciones largas
   - Mejorar calidad de long-term memory

2. **Semantic Compression**

   - Comprimir por similaridad semÃ¡ntica
   - Mantener informaciÃ³n mÃ¡s relevante

3. **User Memory Profiles**

   - Memoria a largo plazo por usuario (no solo sesiÃ³n)
   - Preferencias, lugares favoritos, patrones

4. **Hierarchical Summarization**

   - ResÃºmenes por niveles (hora â†’ dÃ­a â†’ semana)
   - Para usuarios con mucha historia

5. **Memory Pruning Inteligente**
   - Eliminar informaciÃ³n redundante automÃ¡ticamente
   - Mantener solo lo relevante

---

**Ãšltima actualizaciÃ³n**: Diciembre 2024  
**VersiÃ³n**: 2.0  
**Autor**: Sistema de IA
